# -*- coding: utf-8 -*-
"""tag training data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fsd-cJ34iDGJamI1lfLp3HDI_1BUIyW3
"""

import numpy as np
import nltk
import sklearn
import operator
import requests
import csv
import pandas as pd


from nltk.tokenize import RegexpTokenizer   #use this to remove the punctuation
tokenizer = RegexpTokenizer(r'\w+')

nltk.download('stopwords') # If needed
nltk.download('punkt') # If needed
nltk.download('wordnet') # If needed
nltk.download('averaged_perceptron_tagger')

#preprocess the training data to textand location
def preprocess_text(path):
  train_file=open(path).readlines()

  location_train=[]
  content_train_text=[]
  for train_line in train_file:
    train_linesplit=train_line.split("\t")
    content_train_text.append(train_linesplit[1])
    location_train.append(int(train_linesplit[0]))
  return (content_train_text,location_train)

#this is the different types of part-of-speech
noun = ['NN','NNS','NNP','NNPS']
verb = ['VB','VBD','VBG','VBN','VBP','VBZ']
adjective = ['JJ','JJR','JJS']
adverb = ['RB','RBR','RBS']

#count the word in each sentence
def count_tag(text):
  count_tag = []
  for each_sentence in text:
    each_count_tag = [0,0,0,0]
    words = tokenizer.tokenize(each_sentence)
    word_tag = nltk.pos_tag(words)
    for each_word in word_tag:
      if each_word[1] in noun:
        each_count_tag[0] += 1
      elif each_word[1] in verb:
        each_count_tag[1] += 1
      elif each_word[1] in adjective:
        each_count_tag[2] += 1
      elif each_word[1] in adverb:
        each_count_tag[3] += 1
    count_tag.append(each_count_tag)
  print(count_tag)
  return count_tag

#save to .csv file
def save_count_tag(text,file_name):
  try:
    with open(file_name,'w') as f:
      writer = csv.writer(f)
      writer.writerow(['noun','verb','adjective','adverb'])
      count_tag_text = count_tag(text)
      writer.writerows(count_tag_text)
  except FileNotFoundError as e:
      print('Cannot open this file.')
  except IOError as e:
      print('Error in write.')
  print('Compelete.')

#load the file (you need to change the path when you want to do it again)
path_hood_train_text = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/hood/train.data.txt'
path_java_train_text = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/java/train.data.txt'
path_mole_train_text = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/mole/train.data.txt'
path_pitcher_train_text = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/pitcher/train.data.txt'
path_pound_train_text = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/pound/train.data.txt'
path_seal_train_text = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/seal/train.data.txt'
path_spring_train_text = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/spring/train.data.txt'
path_square_train_text = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/square/train.data.txt'
path_trunk_train_text = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/trunk/train.data.txt'
path_yard_train_text = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/yard/train.data.txt'

#get the text of each word
(hood_train_text,hood_train_location) = preprocess_text(path_hood_train_text)
(java_train_text,java_train_location) = preprocess_text(path_java_train_text)
(mole_train_text,mole_train_location) = preprocess_text(path_mole_train_text)
(pitcher_train_text,pitcher_train_location) = preprocess_text(path_pitcher_train_text)
(pound_train_text,pound_train_location) = preprocess_text(path_pound_train_text)
(seal_train_text,seal_train_location) = preprocess_text(path_seal_train_text)
(spring_train_text,spring_train_location) = preprocess_text(path_spring_train_text)
(square_train_text,square_train_location) = preprocess_text(path_square_train_text)
(trunk_train_text,trunk_train_location) = preprocess_text(path_trunk_train_text)
(yard_train_text,yard_train_location) = preprocess_text(path_yard_train_text)

#save to .csv files
save_count_tag(hood_train_text,'hood_train_tag.csv')
save_count_tag(java_train_text,'java_train_tag.csv')
save_count_tag(mole_train_text,'mole_train_tag.csv')
save_count_tag(pitcher_train_text,'pitcher_train_tag.csv')
save_count_tag(pound_train_text,'pound_train_tag.csv')
save_count_tag(seal_train_text,'seal_train_tag.csv')
save_count_tag(spring_train_text,'spring_train_tag.csv')
save_count_tag(square_train_text,'square_train_tag.csv')
save_count_tag(trunk_train_text,'trunk_train_tag.csv')
save_count_tag(yard_train_text,'yard_train_tag.csv')

#read the files
hood_tag = pd.read_csv('hood_train_tag.csv')
java_tag = pd.read_csv('java_train_tag.csv')
mole_tag = pd.read_csv('mole_train_tag.csv')
pitcher_tag = pd.read_csv('pitcher_train_tag.csv')
pound_tag = pd.read_csv('pound_train_tag.csv')
seal_tag = pd.read_csv('seal_train_tag.csv')
spring_tag = pd.read_csv('spring_train_tag.csv')
square_tag = pd.read_csv('square_train_tag.csv')
trunk_tag = pd.read_csv('trunk_train_tag.csv')
yard_tag = pd.read_csv('yard_train_tag.csv')