{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/c1907708/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/c1907708/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7a1dbb40015a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#For Cosine Similarity Calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_sm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "#Importing necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "#The below module is used to calculate the word count and vader sentiment score\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#The below module is used to calculate the tfidf score for a sentence\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#For Cosine Similarity Calculation\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#Necessary import for plotting\n",
    "from bokeh.io import output_file,save\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.palettes import Spectral6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Data\n",
    "# function to convert the text file to dataframe\n",
    "def txt_to_df(position_with_text_file, class_file, mapping_file):\n",
    "    \"\"\"\n",
    "    Function to create a dataframe from three text files: \n",
    "    test.data.txt : The data containing token position and text\n",
    "    test.gold.txt: The text file containing class data\n",
    "    classes_map.txt: The text file containing class names\n",
    "    \"\"\"\n",
    "    num_list = []\n",
    "    text_list = []\n",
    "    class_list = []\n",
    "    \n",
    "    #Block of code to read position_with_text_file to extract token position number and text\n",
    "    with open(position_with_text_file, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            num_list.append(line.split('\\t')[0])\n",
    "            text_list.append(line.split('\\t')[1].strip('\\n'))\n",
    "    \n",
    "    # Block of code to read class_file to extract the class information of the text\n",
    "    with open(class_file, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            class_list.append(line.strip('\\n'))\n",
    "            \n",
    "    #Block of code to read the mapping file to extract each's class name mappings \n",
    "    with open(mapping_file, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            class_map = line\n",
    "            class_map = json.loads(class_map)\n",
    "    \n",
    "    #Creating dataframe from extracted lists\n",
    "    df = pd.DataFrame({'Token_Position': num_list, 'Text List': text_list, 'Class':class_list})\n",
    "    \n",
    "    #Creating a new column to store the class name\n",
    "    df['Class_name'] = df['Class']\n",
    "    df['Class_name'] = df['Class_name'].replace(class_map)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_calculation(text):\n",
    "    \"\"\"\n",
    "    Function to return the count of words in a sentence\n",
    "    \"\"\"\n",
    "    return len(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_calculation(text1, text2):\n",
    "    \"\"\"\n",
    "    Function to calculate the cosine similarity score for text and class name\n",
    "    \"\"\"\n",
    "    text1 = nlp(text1)\n",
    "    text2 = nlp(text2)\n",
    "    return text1.similarity(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(query, document):\n",
    "    \"\"\"\n",
    "    Function to calculate jaccard similarity score for text and class name\n",
    "    \"\"\"\n",
    "    intersection = set(query).intersection(set(document))\n",
    "    union = set(query).union(set(document))\n",
    "    return len(intersection)/len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_dict(doc):\n",
    "    \"\"\"\n",
    "    Function to output the dict containing the words in the corpus and its tfidf score\n",
    "    The output dict will in turn be used as an input in tfidf_score_calculator function\n",
    "    \"\"\"\n",
    "    tfidf_vectorizer=TfidfVectorizer(use_idf=True)\n",
    "    tfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(doc)\n",
    "    # get the first vector out (for the first document)\n",
    "    first_vector_tfidfvectorizer=tfidf_vectorizer_vectors[0]\n",
    "\n",
    "    # place tf-idf values in a pandas data frame\n",
    "    df1 = pd.DataFrame(first_vector_tfidfvectorizer.T.todense(), index=tfidf_vectorizer.get_feature_names(), columns=[\"tfidf\"])\n",
    "    df1.sort_values(by=[\"tfidf\"],ascending=False)\n",
    "    tfidf_score_dict = df1['tfidf'].to_dict()\n",
    "    return tfidf_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_score_calculator(lis, tfidf_dict):\n",
    "    \"\"\"\n",
    "    Function to calculate tfidf score for text and class name\n",
    "    \"\"\"\n",
    "    tf_idf_score_list = []\n",
    "    tfidf_keys = list(tfidf_dict.keys())\n",
    "    for text in lis:\n",
    "        tf_idf_score = 0\n",
    "        for token in word_tokenize(text):\n",
    "            if token in tfidf_keys:\n",
    "                tf_idf_score += tfidf_dict[token]\n",
    "            else:\n",
    "                tf_idf_score += 0\n",
    "        tf_idf_score_list.append(tf_idf_score)   \n",
    "    return (lis, tf_idf_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_table(df, group_by_col, agg_col_list, report_name):\n",
    "    \"\"\"\n",
    "    Function to calculate the five num summary for the input columns grouped by group_by_col.\n",
    "    Also, the ouput will be written as a csv file with given report_name\n",
    "    \"\"\"\n",
    "    five_num_summary = ['min', 'max', 'mean', 'median', 'std']\n",
    "    table = df.groupby(group_by_col).agg({agg_col_list:five_num_summary})\n",
    "\n",
    "    table.to_csv(report_name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bokeh_bar_plot(df, group_by_col, agg_col, metric, folder_path):\n",
    "    \"\"\"\n",
    "    Function to generate the Bokeh Bar chart for the metric\n",
    "    \"\"\"\n",
    "    from bokeh.core.validation import silence\n",
    "    from bokeh.core.validation.warnings import EMPTY_LAYOUT\n",
    "    silence(EMPTY_LAYOUT, True)                       \n",
    "    #Generating agg_df\n",
    "    groupdf = df.groupby(group_by_col).agg({agg_col:metric})\n",
    "    groupdf = groupdf.reset_index()\n",
    "    groupdf[agg_col] = round(groupdf[agg_col], 2)\n",
    "    plot_file_name = folder_path+agg_col+\"_\"+metric+\"_plot\"+'.html'\n",
    "    plot_title = metric.capitalize()+\" Plot of \"+agg_col\n",
    "    source = ColumnDataSource(data=dict(x_col=groupdf[group_by_col], y_col=groupdf[agg_col], color=Spectral6))\n",
    "    labels = LabelSet(x='x_col', y='y_col', text='y_col', level='glyph',x_offset=-13.5, y_offset=0, \n",
    "                      source=source, render_mode='canvas')\n",
    "    # Set the x_range to the list of categories above\n",
    "    p = figure(x_range=groupdf[group_by_col], plot_width=600, plot_height=300, title=plot_title)\n",
    "    # Categorical values can also be used as coordinates\n",
    "    p.vbar(x='x_col', top='y_col', color='color', width=0.5, source=source)\n",
    "    p.add_layout(labels)\n",
    "    # Set some properties to make the plot look better\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.y_range.start = 0\n",
    "    \n",
    "    #Saving the plot\n",
    "    output_file(plot_file_name)\n",
    "    save(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Framing the dataframe from all the input text files\n",
    "def end_function_ouput(text_file, class_file, class_map_file, word, sub_folder):\n",
    "    \"\"\"\n",
    "    Function to process the given three text files and generate tables and plots out of it\n",
    "    \"\"\"\n",
    "    df = txt_to_df(text_file, class_file, class_map_file)\n",
    "\n",
    "    # Calculating Vader sentiment score and storing it in a column\n",
    "    df['vader_sentiment_score'] = df['Text List'].apply(analyzer.polarity_scores)\n",
    "\n",
    "    #Calculating word count for Text\n",
    "    df['Text_Word_Count'] = df['Text List'].map(word_count_calculation)\n",
    "\n",
    "    #Creating a column and use it to store cosine similarity score\n",
    "    df['Cosine_Similarity_Score'] = df[['Text List', 'Class_name']].apply(lambda x:similarity_calculation(*x), axis=1)\n",
    "\n",
    "    #Creating a column and use it to store Jaccard similarity score\n",
    "    df['Jaccard_similarity_score'] = df[['Class_name', 'Text List']].apply(lambda x:jaccard_similarity(*x), axis=1)\n",
    "\n",
    "    #Code block to calculate the tfidf scores for a text and store it as column\n",
    "    tfidf_score_dict = tf_idf_dict(list(df['Text List']))\n",
    "\n",
    "    lis, score_list = tfidf_score_calculator(list(df['Text List']), tfidf_score_dict)\n",
    "\n",
    "    df['tf_idf_score'] = score_list\n",
    "\n",
    "    # Code block to store all the parameters in the dict in a separate column\n",
    "    df['Vader_Positive_Score'] = df['vader_sentiment_score'].apply(lambda x:x['pos'])\n",
    "    df['Vader_Negative_Score'] = df['vader_sentiment_score'].apply(lambda x:x['neg'])\n",
    "    df['Vader_Neutral_Score'] = df['vader_sentiment_score'].apply(lambda x:x['neu'])\n",
    "    df['Vader_Compound_Score'] = df['vader_sentiment_score'].apply(lambda x:x['compound'])\n",
    "\n",
    "    scores_list = [\"Text_Word_Count\", \"Cosine_Similarity_Score\", \"Jaccard_similarity_score\", \"tf_idf_score\", \n",
    "                    \"Vader_Positive_Score\",\"Vader_Neutral_Score\", \"Vader_Negative_Score\", \"Vader_Compound_Score\"]\n",
    "    metrics_list = ['min', 'max', 'mean', 'median', 'std']\n",
    "\n",
    "    #Table path derivation\n",
    "    Table_path=os.getcwd()+'\\\\'+\"Output\\\\\"+word+\"\\\\\"+\"Tables\"+\"\\\\\"+sub_folder+\"\\\\\"\n",
    "\n",
    "    if not os.path.exists(Table_path):\n",
    "        os.makedirs(Table_path)\n",
    "\n",
    "    #Plots plot derivation\n",
    "    for score in scores_list:\n",
    "        plot_path = os.getcwd()+'\\\\'+\"Output\\\\\"+word+\"\\\\\"+\"Plots\"+\"\\\\\"+sub_folder+\"\\\\\"+score+\"\\\\\"\n",
    "        if not os.path.exists(plot_path):\n",
    "            os.makedirs(plot_path)\n",
    "\n",
    "    for score in scores_list:\n",
    "        report_name = Table_path+score\n",
    "        save_table(df, group_by_col=\"Class_name\",agg_col_list= score, report_name=report_name)\n",
    "        for metric in metrics_list:\n",
    "            folder_path = os.getcwd()+'\\\\'+\"Output\\\\\"+word+\"\\\\\"+\"Plots\"+\"\\\\\"+sub_folder+\"\\\\\"+score+\"\\\\\"\n",
    "            generate_bokeh_bar_plot(df, 'Class_name', score, metric, folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
