{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Groupwork_preprocessing.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3VeUyvAC4jd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "48695401-b3d6-4b85-a1a8-6eac2a6d0f21"
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import sklearn\n",
        "import operator\n",
        "import requests\n",
        "nltk.download('stopwords') # If needed\n",
        "nltk.download('punkt') # If needed\n",
        "nltk.download('wordnet') # If needed"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_CIiFmvDCCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the data which content text\n",
        "def preprocess_text(path):\n",
        "  train_file=open(path).readlines()\n",
        "\n",
        "  location_train=[]\n",
        "  content_train_text=[]\n",
        "  for train_line in train_file:\n",
        "    train_linesplit=train_line.split(\"\\t\")\n",
        "    content_train_text.append(train_linesplit[1])\n",
        "    location_train.append(int(train_linesplit[0]))\n",
        "  return (content_train_text,location_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrUkW0VXD-Ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the gold data\n",
        "def preprocess_gold(path):\n",
        "  train_gold_file=open(path).readlines()\n",
        "  Y_train=[]\n",
        "  for train_gold_line in train_gold_file:\n",
        "    train_gold_linesplit=train_gold_line.split(\"\\n\")\n",
        "    Y_train.append(int(train_gold_linesplit[0]))\n",
        "  return Y_train\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PTzSQN9ERCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_hood_train_text = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/hood/train.data.txt'\n",
        "path_hood_train_gold = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/hood/train.gold.txt'\n",
        "\n",
        "(hood_train_text,hood_train_location) = preprocess_text(path_hood_train_text)\n",
        "hood_train_gold = preprocess_gold(path_hood_train_gold)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAxo8J1uFJCN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "74bf6d6e-418c-4071-fbec-20217c47b434"
      },
      "source": [
        "for train_line in hood_train_text[:10]:\n",
        "  print (train_line)\n",
        "# print (hood_train_text[:5])\n",
        "print (hood_train_location[:5])\n",
        "print (hood_train_gold[:50])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "later she was shot and severely beaten by the hood in her home in retaliation for having beaten jigsaw , a member of his fledgling super-criminal organization .\n",
            "\n",
            "this coat has a regular hood .\n",
            "\n",
            "he battles the hood .\n",
            "\n",
            "during the dark reign storyline , white rabbit appears as a member of the hood 's gang .\n",
            "\n",
            "medusa has joined the group as well ( filling in for the presumably deceased black bolt ) after learning that the hood is targeting them for the infinity gems , seeking to reform the infinity gauntlet and regain the power he lost after the siege of asgard .\n",
            "\n",
            "'' dead end '' ( # 6 -- 10 , annual # 1 ) the hood 's crime organization grows at an alarming rate , eluding the authorities of new york city , most of the superhero population , and norman osborn and h.a.m.m.e.r. .\n",
            "\n",
            "a person who looks like the original blackout appears as part of the hood 's alliance with super-powered heroes .\n",
            "\n",
            "in dark reign crossover , he is one among many supervillains who joined the hood 's crime syndicate .\n",
            "\n",
            "ringer later assisted hood into fighting counter force .\n",
            "\n",
            "the surviving blood brother later joins the hood and his criminal empire , and helps fight the alien shape-shifting race the skrulls during the skrull invasion of earth .\n",
            "\n",
            "[9, 5, 3, 14, 21]\n",
            "[0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 0, 2, 2, 1, 0, 0, 0, 1, 1, 1, 2, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}