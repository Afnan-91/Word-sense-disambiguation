{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w2v_googlenews.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGqKSeOvEms6",
        "colab_type": "code",
        "outputId": "c110c0d3-29c1-4715-9033-7b2c8aaf75f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from google.colab import files\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import FastText\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bdc-W2MEtNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "836b88de-1026-40ee-a664-ffb9d0ccf017"
      },
      "source": [
        "\n",
        "punct =['.',',',';',':','!','\\'', '?', '\"', '(', ')', '[', ']', '<', '>', '\\\\', '/']\n",
        "english_stop_words = stopwords.words('english')\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "words = ['hood', 'java', 'mole', 'pitcher', 'pound', 'seal', 'spring', 'square', 'trunk', 'yard']\n",
        "\n",
        "def get_list_tokens(string):\n",
        "\tsentence_split = nltk.tokenize.sent_tokenize(string)\n",
        "\tlist_tokens = []\n",
        "\tfor sentence in sentence_split:\n",
        "\t\tlist_tokens_sentence = nltk.tokenize.word_tokenize(sentence)\n",
        "\t\tfor token in list_tokens_sentence:\n",
        "\t\t\tlist_tokens.append(lemmatizer.lemmatize(token).lower())\n",
        "\n",
        "\treturn list_tokens\n",
        "\n",
        "def remove_stop_words(list_tokens):\n",
        "\tclean_list_tokens = []\n",
        "\tfor token in list_tokens:\n",
        "\t\tif token not in english_stop_words:\n",
        "\t\t\tclean_list_tokens.append(token)\n",
        "\n",
        "\treturn clean_list_tokens\n",
        "\n",
        "def remove_punct(list_tokens):\n",
        "\tno_punct = []\n",
        "\tfor i in list_tokens:\n",
        "\t\ti = re.sub(r'[^\\w\\s]','',i)\n",
        "\t\tif i:\n",
        "\t\t\tno_punct.append(i)\n",
        "\t# no_punct = [i for i in list_tokens if i not in punct]\n",
        "\treturn no_punct\n",
        "\n",
        "def convertTow2v(list_tokens, selected_features, w2v_vector):\n",
        "\t\tw2v = np.zeros((len(list_tokens), len(selected_features), 300))\n",
        "\t\tset_s_f = set(selected_features)\n",
        "\t\tfor i in range(len(list_tokens)):\n",
        "\t\t\t# in case some training data tokens are not in features\n",
        "\t\t\tinters = set(list_tokens[i]).intersection(set_s_f)\n",
        "\t\t\tfor word in inters:\n",
        "\t\t\t\tj = selected_features.index(word)\n",
        "\t\t\t\tw2v[i][j] = w2v_vector[j]\n",
        "\n",
        "\t\tw2v = np.sum(w2v, axis = 1)\n",
        "\n",
        "\t\treturn w2v\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# df = pd.DataFrame(stats_all, columns=['accuracy', 'precision', 'recall', 'fscore'], index=words)\n",
        "# print(df)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrCo4B2pFqZj",
        "colab_type": "code",
        "outputId": "6a3c402c-47d3-498e-ec6b-f1b88ca9a96e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "model2 = api.load('word2vec-google-news-300')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[=================================================-] 99.8% 1659.4/1662.8MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ijorSM-EzG8",
        "colab_type": "code",
        "outputId": "e0fee189-d5f9-4ac2-9221-2e66efd21b4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "stats_all = []\n",
        "for word in words:\n",
        "    \n",
        "    # train_text = files.upload()\n",
        "    # train_label = files.upload()\n",
        "    # test_text = files.upload()\n",
        "    # test_label = files.upload()\n",
        "\n",
        "    train_text = pd.read_csv('/content/drive/My Drive/CoarseWSD_P2/{}/train.data.txt'.format(word),\n",
        "                             sep='\\t',\n",
        "                             names=['index', 'sentence'])\n",
        "    train_label = pd.read_csv('/content/drive/My Drive/CoarseWSD_P2/{}/train.gold.txt'.format(word),\n",
        "                              sep='\\t',\n",
        "                              names=['label'])\n",
        "\n",
        "    test_text = pd.read_csv('/content/drive/My Drive/CoarseWSD_P2/{}/test.data.txt'.format(word),\n",
        "                            sep='\\t',\n",
        "                            names=['index', 'sentence'])\n",
        "    test_label = pd.read_csv('/content/drive/My Drive/CoarseWSD_P2/{}/test.gold.txt'.format(word),\n",
        "                             sep='\\t',\n",
        "                             names=['label'])\n",
        "\n",
        "\n",
        "    # merge train date with labels data in one table\n",
        "    train = pd.merge(train_text, train_label, left_index=True, right_index=True)\n",
        "    test = pd.merge(test_text, test_label, left_index=True, right_index=True)\n",
        "\n",
        "\n",
        "    # preprocess the sentences\n",
        "    list_tokens = []\n",
        "    for i in range(0, len(train.sentence)):\n",
        "        sentence_tokens = get_list_tokens(train.sentence[i])\n",
        "        rm_st = remove_stop_words(sentence_tokens)\n",
        "        rm_punct = remove_punct(rm_st)\n",
        "        list_tokens.append(rm_punct)\n",
        "        # update cell\n",
        "        train.at[i,'sentence']=' '.join(rm_punct)\n",
        "\n",
        "    test_tokens = []\n",
        "    for i in range(0, len(test.sentence)):\n",
        "        sentence_tokens = get_list_tokens(test.sentence[i])\n",
        "        rm_st = remove_stop_words(sentence_tokens)\n",
        "        rm_punct = remove_punct(rm_st)\n",
        "        test_tokens.append(rm_punct)\n",
        "        # update cell\n",
        "        test.at[i,'sentence']=' '.join(rm_punct)\n",
        "\n",
        "\n",
        "    list_rows = train['sentence']\n",
        "    vectorizer = TfidfVectorizer(max_features=1000)\n",
        "    X = vectorizer.fit(list_rows)\n",
        "\n",
        "    selected_features = vectorizer.get_feature_names()\n",
        "\n",
        "\n",
        "    # Size is the number of dimensions of the embeddings we are going to learn\n",
        "    # Window is the size considered for context of a target word\n",
        "    # Min count is the minimum number of times that a word need to occur to be learnt\n",
        "    model = Word2Vec(list_tokens, size=300, window=5, min_count=1)\n",
        "    # model = api.load('word2vec-google-news-300')\n",
        "    # model = FastText(size=100, window=3, min_count=1)\n",
        "    # model.build_vocab(sentences=list_tokens)\n",
        "    model.train(list_tokens, total_examples=len(list_tokens), epochs=100)\n",
        "    # model.train(list_tokens)\n",
        "    # model = Word2Vec.load('word2vec-google-news-300')\n",
        "    not_in_model = model2.doesnt_match(selected_features)\n",
        "    # print(len(not_in_model))\n",
        "\n",
        "    # selected_features = selected_features - not_in_model\n",
        "    w2v_vector = [model2[feature] if feature in not_in_model else model[feature] for feature in selected_features ]\n",
        "    # w2v_vector = model[selected_features]\n",
        "\n",
        "\n",
        "    w2v = convertTow2v(list_tokens, selected_features, w2v_vector)\n",
        "    w2v_test = convertTow2v(test_tokens, selected_features, w2v_vector)\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=3)\n",
        "    knn.fit(w2v, train.label)\n",
        "\n",
        "    # for sentence in w2v_test:\n",
        "    prediction = knn.predict(w2v_test)\n",
        "\n",
        "    accuracy = accuracy_score(test.label, prediction)\n",
        "    precision, recall, fscore, support = precision_recall_fscore_support(test.label, prediction, average='macro', zero_division=0)\n",
        "    stats = [accuracy, precision, recall, fscore]\n",
        "    stats_all.append(stats)\n",
        "\n",
        "\n",
        "    print(word)\n",
        "    print(stats)\n",
        "\n",
        "df = pd.DataFrame(stats_all, columns=['accuracy', 'precision', 'recall', 'fscore'], index=words)\n",
        "print(df)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "hood\n",
            "[0.6219512195121951, 0.4839406207827261, 0.4818231413976095, 0.48191846708316416]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "java\n",
            "[0.9823742871954381, 0.9810062471203621, 0.9819358014075263, 0.9814661379620608]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mole\n",
            "[0.7621359223300971, 0.7608312020460357, 0.7022416713721061, 0.7254659291995127]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "pitcher\n",
            "[0.9932600212841434, 0.623218738867118, 0.6137809090410659, 0.6183075004453946]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "pound\n",
            "[0.7938144329896907, 0.5232358003442341, 0.5310344827586206, 0.5245098039215687]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "seal\n",
            "[0.8402203856749312, 0.7480073602598354, 0.7087959032320827, 0.7222124430362417]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "spring\n",
            "[0.8643326039387309, 0.8677097505668935, 0.8298323282651121, 0.8459062841591667]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "square\n",
            "[0.8792270531400966, 0.9027573529411765, 0.7255825699619776, 0.7768634395503282]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trunk\n",
            "[0.6753246753246753, 0.5401382243487507, 0.4846757852077001, 0.49538461538461537]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "yard\n",
            "[0.8055555555555556, 0.42028985507246375, 0.47540983606557374, 0.4461538461538461]\n",
            "         accuracy  precision    recall    fscore\n",
            "hood     0.621951   0.483941  0.481823  0.481918\n",
            "java     0.982374   0.981006  0.981936  0.981466\n",
            "mole     0.762136   0.760831  0.702242  0.725466\n",
            "pitcher  0.993260   0.623219  0.613781  0.618308\n",
            "pound    0.793814   0.523236  0.531034  0.524510\n",
            "seal     0.840220   0.748007  0.708796  0.722212\n",
            "spring   0.864333   0.867710  0.829832  0.845906\n",
            "square   0.879227   0.902757  0.725583  0.776863\n",
            "trunk    0.675325   0.540138  0.484676  0.495385\n",
            "yard     0.805556   0.420290  0.475410  0.446154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-mvlNRQF2Dg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "44a5b4d2-3b6f-4c51-e795-4e5c807c38b7"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Figure.show of <Figure size 2160x2160 with 10 Axes>>\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8ckkBQxkzaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}