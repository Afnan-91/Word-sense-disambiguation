# -*- coding: utf-8 -*-
"""tag test data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r4Vqvt3ZO-ZU1XUXXBhzi-eVf7-RcdHo
"""

import numpy as np
import nltk
import sklearn
import operator
import requests
import csv
import pandas as pd


from nltk.tokenize import RegexpTokenizer   #use this to remove the punctuation
tokenizer = RegexpTokenizer(r'\w+')

nltk.download('stopwords') # If needed
nltk.download('punkt') # If needed
nltk.download('wordnet') # If needed
nltk.download('averaged_perceptron_tagger')
nltk.download('universal_tagset')
#preprocess the test data to textand location
def preprocess_text(path):
  test_file=open(path).readlines()

  location_test=[]
  content_test_text=[]
  for test_line in test_file:
    test_linesplit=test_line.split("\t")
    content_test_text.append(test_linesplit[1])
    location_test.append(int(test_linesplit[0]))
  return (content_test_text,location_test)


#count the word in each sentence
def count_tag(text):
  count_tag = []
  for each_sentence in text:
    each_count_tag = [0,0,0,0]
    words = tokenizer.tokenize(each_sentence)
    word_tag = nltk.pos_tag(words,tagset='universal')
    for each_word in word_tag:
      if each_word[1] == 'NOUN':
        each_count_tag[0] += 1
      elif each_word[1] == 'VERB':
        each_count_tag[1] += 1
      elif each_word[1] == 'ADJ':
        each_count_tag[2] += 1
      elif each_word[1] == 'ADV':
        each_count_tag[3] += 1
    count_tag.append(each_count_tag)
  print(count_tag)
  return count_tag

#save to .csv file
def save_count_tag(text,file_name):
  try:
    with open(file_name,'w') as f:
      writer = csv.writer(f)
      writer.writerow(['noun','verb','adjective','adverb'])
      count_tag_text = count_tag(text)
      writer.writerows(count_tag_text)
  except FileNotFoundError as e:
      print('Cannot open this file.')
  except IOError as e:
      print('Error in write.')
  print('Compelete.')

#load the file (you need to change the path when you want to do it again)
path_hood_test_text = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/hood/test.data.txt'
path_java_test_text = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/java/test.data.txt'
path_mole_test_text = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/mole/test.data.txt'
path_pitcher_test_text = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/pitcher/test.data.txt'
path_pound_test_text = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/pound/test.data.txt'
path_seal_test_text = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/seal/test.data.txt'
path_spring_test_text = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/spring/test.data.txt'
path_square_test_text = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/square/test.data.txt'
path_trunk_test_text = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/trunk/test.data.txt'
path_yard_test_text = '/content/drive/My Drive/AoML/Group CS/CoarseWSD_P2/yard/test.data.txt'

#get the text of each word
(hood_test_text,hood_test_location) = preprocess_text(path_hood_test_text)
(java_test_text,java_test_location) = preprocess_text(path_java_test_text)
(mole_test_text,mole_test_location) = preprocess_text(path_mole_test_text)
(pitcher_test_text,pitcher_test_location) = preprocess_text(path_pitcher_test_text)
(pound_test_text,pound_test_location) = preprocess_text(path_pound_test_text)
(seal_test_text,seal_test_location) = preprocess_text(path_seal_test_text)
(spring_test_text,spring_test_location) = preprocess_text(path_spring_test_text)
(square_test_text,square_test_location) = preprocess_text(path_square_test_text)
(trunk_test_text,trunk_test_location) = preprocess_text(path_trunk_test_text)
(yard_test_text,yard_test_location) = preprocess_text(path_yard_test_text)

#save to .csv files
save_count_tag(hood_test_text,'hood_test_tag.csv')
save_count_tag(java_test_text,'java_test_tag.csv')
save_count_tag(mole_test_text,'mole_test_tag.csv')
save_count_tag(pitcher_test_text,'pitcher_test_tag.csv')
save_count_tag(pound_test_text,'pound_test_tag.csv')
save_count_tag(seal_test_text,'seal_test_tag.csv')
save_count_tag(spring_test_text,'spring_test_tag.csv')
save_count_tag(square_test_text,'square_test_tag.csv')
save_count_tag(trunk_test_text,'trunk_test_tag.csv')
save_count_tag(yard_test_text,'yard_test_tag.csv')

#read the files
hood_tag = pd.read_csv('hood_test_tag.csv')
java_tag = pd.read_csv('java_test_tag.csv')
mole_tag = pd.read_csv('mole_test_tag.csv')
pitcher_tag = pd.read_csv('pitcher_test_tag.csv')
pound_tag = pd.read_csv('pound_test_tag.csv')
seal_tag = pd.read_csv('seal_test_tag.csv')
spring_tag = pd.read_csv('spring_test_tag.csv')
square_tag = pd.read_csv('square_test_tag.csv')
trunk_tag = pd.read_csv('trunk_test_tag.csv')
yard_tag = pd.read_csv('yard_test_tag.csv')